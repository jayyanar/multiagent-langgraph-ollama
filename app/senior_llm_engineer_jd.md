
# Senior Software Engineering Manager – LLM Platforms & Frameworks (Azure & GCP)

## About the Role

Wells Fargo is seeking a **Senior Software Engineering Manager** to lead the design, development, and deployment of **Large Language Model (LLM) solutions** across enterprise use cases, with a focus on building **robust, secure, and scalable platforms** using **Azure OpenAI Service** and **Google Cloud Vertex AI**. This role is ideal for a technical leader passionate about advancing the application of LLMs and agentic frameworks in a modern, cloud-native enterprise environment.

---

## Key Responsibilities

- Lead architecture, development, and deployment of LLM platforms and services, ensuring they are **enterprise-ready and production-grade**.
- Manage engineering teams building core capabilities such as **retrieval-augmented generation (RAG), prompt engineering, multi-agent orchestration**, and LLM evaluation pipelines.
- Oversee end-to-end solution delivery leveraging **Azure OpenAI, GCP Vertex AI**, and associated cloud-native components (Kubernetes, BigQuery, Azure Functions, etc.).
- Partner with AI/ML research, cloud, and security teams to ensure seamless integration of LLM capabilities into business workflows.
- Establish best practices for **LLM observability, responsible AI, testing, and continuous improvement**.
- Collaborate with business stakeholders to translate requirements into scalable AI-powered applications.
- Promote reusability through **reference architectures, shared services, and framework standardization**.
- Contribute hands-on to the design and implementation of **core GenAI services, microservices, and data flows**.

---

## Required Qualifications

- **8+ years** of experience in software engineering, with **3+ years managing high-performing engineering teams**.
- Proven experience delivering **LLM-powered applications** in production, including usage of **Azure OpenAI Service** and/or **Google Vertex AI**.
- Deep understanding of **LLM frameworks** (LangChain, Semantic Kernel, LlamaIndex, Haystack, etc.) and **multi-agent orchestration techniques**.
- Strong software engineering background with proficiency in **Python, Java**, and REST/gRPC service design.
- Experience with **cloud-native architectures**, containerization (Docker), Kubernetes, and CI/CD pipelines.
- Knowledge of **LLM evaluation techniques, prompt tuning, fine-tuning strategies**, and GenAI observability tools.
- Strong understanding of **SDLC, Agile methodologies**, and AI/ML lifecycle management.

---

## Preferred Qualifications

- Master’s or PhD in **Computer Science, Machine Learning, AI, or Engineering**.
- Experience building **agentic systems**, tools-based reasoning workflows, or RAG-enhanced QA systems.
- Familiarity with **MCP (Model Context Protocol)** or similar approaches for cross-agent context sharing.
- Exposure to **data privacy, ethical AI practices**, and enterprise compliance frameworks.
- Experience with **streaming data, vector databases** (e.g., Pinecone, Weaviate, FAISS), and hybrid RAG architectures.
- Strong thought leadership and ability to mentor engineering teams in emerging LLM technologies.

---

## Leadership Expectations

- **Innovate Boldly:** Champion experimentation and innovation in GenAI and LLM engineering.
- **Deliver Excellence:** Balance speed with rigor, ensuring systems are scalable, secure, and maintainable.
- **Empower Teams:** Inspire, coach, and grow diverse engineering talent.
- **Lead Transparently:** Communicate clearly across technical and business audiences.
- **Think Strategically:** Align technology roadmaps with long-term enterprise AI goals.
